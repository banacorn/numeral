\documentclass[../thesis.tex]{subfiles}
\begin{document}

\section{Properties of Natural Numbers and Equational Reasoning}\label{eq-reasoning}
% [draft]

With propositional equality at our disposal, we will demonstrate how to prove
properties such as the commutative property of addition.
As proofs get more complicated, we will introduce equational reasoning, a
powerful tool that makes proving easier.

\paragraph{Right identity of addition}

Recap the definition of addition on {\lstinline|ℕ|}.

\begin{lstlisting}
_+_ : ℕ → ℕ → ℕ
zero  + y = y
suc x + y = suc (x + y)
\end{lstlisting}

{\lstinline|_+_|} is defined by induction on the first argument. That means we
get the \textit{left identity} of addition for free, as {\lstinline|zero + y|}
and {\lstinline|y|} are \textit{computationally equal}. However, this is not the
case for the \textit{right identity} of addition. It has to be proven explicitly.

\begin{lstlisting}
+-right-identity : (n : ℕ) → n + 0 ≡ n
+-right-identity zero    = ?0
+-right-identity (suc n) = ?1
\end{lstlisting}

By induction on the only argument, we get two sub-goals:

\begin{lstlisting}
?0 : 0 ≡ 0
?1 : suc (n + 0) ≡ suc n
\end{lstlisting}

{\lstinline|?0|} can be trivially proven with {\lstinline|refl|}.
As for {\lstinline|?1|}, we see that its type looks a lot like the proposition
we are proving, except that both sides of the equation are "coated" with a {\lstinline|suc|}.
With {\lstinline|cong suc : ∀ {x y} → x ≡ y → suc x ≡ suc y|}, we could substitute
a term in {\lstinline|suc|} with another if they are equal, and finish
the proof by recursively calling itself with a \textit{smaller} argument.

\begin{lstlisting}
+-right-identity : ∀ n → n + 0 ≡ n
+-right-identity zero    = refl
+-right-identity (suc n) = cong suc (+-right-identity n)
\end{lstlisting}

\paragraph{Moving suc to the other side}

This is an essential lemma for proving more advanced theorems.
The proof also follows a similar pattern as that of {\lstinline|+-right-identity|}.
\footnote{In fact, all of these proofs (hence programs) can be generalized with
a \textit{fold}, but that is not the point here.}

\begin{lstlisting}
+-suc : ∀ m n → m + suc n ≡ suc (m + n)
+-suc zero    n = refl
+-suc (suc m) n = cong suc (+-suc m n)
\end{lstlisting}

\paragraph{Commutative property of addition}

Similarly, by induction on the first argument, we get two sub-goals:

\begin{lstlisting}
+-comm : ∀ m n → m + n ≡ n + m
+-comm zero    n = ?0
+-comm (suc m) n = ?1

?0 : n           ≡ m + zero
?1 : suc (m + n) ≡ m + suc n
\end{lstlisting}

{\lstinline|?0|} can be solved with {\lstinline|+-right-identity|} with a "twist".
The symmetry of equality {\lstinline|sym|} enables us to swap both sides of an equation.

\begin{lstlisting}
+-comm zero    n = sym (+-right-identity n)
\end{lstlisting}

However, it is not obvious how to solve {\lstinline|?1|} straight out.
The proof has to be break into two steps:

\begin{enumerate}
    \item Apply {\lstinline|+-suc|} with {\lstinline|sym|} to the right-hand side
    of the equation to get {\lstinline|suc (m + n) ≡ suc (n + m)|}.
    \item Apply the induction hypothesis to {\lstinline|cong suc|}.
\end{enumerate}

These small pieces of proofs are glued back together with the transitivity of
equality {\lstinline|trans|}.

\begin{lstlisting}
+-comm (suc m) n = trans (cong suc (+-comm m n)) (sym (+-suc n m))
\end{lstlisting}

\subsection{Equational Reasoning}

We see that proofs are composable just like programs.
However, look at the line we have just proven above:

\begin{lstlisting}
trans (cong suc (+-comm m n)) (sym (+-suc n m))
\end{lstlisting}

It is difficult to see what is going on in between these clauses, and it could
get only worse as propositions get more complicated.
Imagine having dozens of {\lstinline|trans|}, {\lstinline|sym|} and {\lstinline|cong|}
spreading everywhere.

Fortunately, these complex proofs can be written in a concise and modular manner
with a simple yet powerful technique called \textit{equational reasoning}.
Agda's flexible mixfix syntax allows the technique to be implemented with just
a few combinators\cite{erikhesselinkpaulvisschers2008}.

This is best illustrated by an example:

\begin{lstlisting}
+-comm : ∀ m n → m + n ≡ n + m
+-comm zero    n = sym (+-right-identity n)
+-comm (suc m) n =
    begin
        suc m + n
    ≡⟨ refl ⟩
        suc (m + n)
    ≡⟨ cong suc (+-comm m n) ⟩
        suc (n + m)
    ≡⟨ sym (+-suc n m) ⟩
        n + suc m
    ∎
\end{lstlisting}

With equational reasoning, we can see how an expression equates with another,
step by step, justified with theorems. The first and the last step corresponds to
two sides of the equation of a proposition. {\lstinline|begin_|} marks the beginning
of a reasoning; {\lstinline|_≡⟨_⟩_|} chains two expressions with the justification
placed in between; {\lstinline|_∎|} marks the end of a reasoning (\textit{QED}).

\subsubsection{Anatomy of Equational Reasoning}

A typical equational reasoning can often be broken down into \textbf{three} parts.

\begin{enumerate}
    \item
        Starting from the left-hand side of the equation, through a series of steps
        , the expression will be "arranged" into a form that allows the induction
        hypothesis to be applied.
        In the following example of {\lstinline|+-comm|}, nothing needs to be arranged
        because these two expressions are computationally equal
        (the {\lstinline|refl|} can be omitted).

        \begin{lstlisting}
            begin
                suc m + n
            ≡⟨ refl ⟩
                suc (m + n)
        \end{lstlisting}
    \item
        {\lstinline|m + n|} emerged as part of the proposition which enables us
        to apply the induction hypothesis.

        \begin{lstlisting}
                suc (m + n)
            ≡⟨ cong suc (+-comm m n) ⟩
                suc (n + m)
        \end{lstlisting}
    \item
        After applying the induction hypothesis, the expression are then "rearranged"
        into the right-hand side of the equation, hence completes the proof.

        \begin{lstlisting}
                suc (n + m)
            ≡⟨ sym (+-suc n m) ⟩
                n + suc m
            ∎
        \end{lstlisting}
\end{enumerate}

\paragraph{arranging expressions}

To arrange an expression into the shape we desire, while remaining equal.
We need properties such as commutativity or associativity of some operator,
or distributive properties when there is more than one operator.

The operators we will be dealing with often comes with these properties.
Take addition and multiplication, for example;
together they form a nice semiring structure.

\paragraph{substituting equals for equals}

Sometimes there is only a part of an expression needs to be substituted.
Say, we have a proof {\lstinline|eq : X ≡ Y|}, and we want to substitute {\lstinline|X|}
for {\lstinline|Y|} in a more complex expression {\lstinline|a b (c X) d|}.
We could ask {\lstinline|cong|} to "target" the part to substitute by supplying a
function like this:

\begin{lstlisting}
λ w → a b (c w) d
\end{lstlisting}

Which abstracts the part we want to substitute away, such that:

\begin{lstlisting}
cong (λ w → a b (c w) d) eq : a b (c X) d ≡ a b (c Y) d
\end{lstlisting}

\subsection{Preorder reasoning}

These combinators can be further generalized to support \textit{preorder reasoning}.
Preorders are {\lstinline|reflexive|} and {\lstinline|transitive|}, that means
expressions can be chained with a series of relations just like equational reasoning.

Suppose we already have {\lstinline|m≤m+n : ∀ m n → m ≤ m + n|} and want to
prove a slightly different theorem.

\begin{lstlisting}
m≤n+m : ∀ m n → m ≤ n + m
m≤n+m m n =
    start
        m
    ≤⟨ m≤m+n m n ⟩
        m + n
    ≈⟨ +-comm m n ⟩
        n + m
    □
\end{lstlisting}

Where {\lstinline|_≤⟨_⟩_|} and {\lstinline|_≈⟨_⟩_|} are respectively transitive
and reflexive combinators.\footnote{Combinators for preorder reasoning are
renamed to prevent conflictions with equational reasoning.}
Step by step, starting from the left-hand side of the relation, expressions get
greater and greater as it reaches the right-hand side the relation.

\subsubsection{Anatomy of Preorder Reasoning}

Similar to that of equation reasoning, a typical preorder reasoning can also be
broken down into parts. Since an equivalence relation is also a preorder, every
steps of equational reasoning can also be found in preorder reasoning.

\paragraph{monotonicity of operators}

In equational reasoning, we could substitute part of an expression with something
equal with {\lstinline|cong|} because {\lstinline|_≡_|} is congruent.
However, we cannot substitute part of an expression with something \textit{greater}
in general.
Take \textit{monus} \footnote{Monus, or \textit{truncated subtraction}, is a
kind of subtraction that never goes negative when the subtrahend is greater then
the minued.} {\lstinline|_∸_|} for example:

\begin{lstlisting}
f : ∀ m n
    → (prop : m ≤ n)
    → m ∸ m ≤ m ∸ n
f m n prop =
    start
        m ∸ m
    ≤⟨ ? ⟩
        m ∸ n
    □
\end{lstlisting}

The proposition {\lstinline|f|} as seen above can only be disapproved, because
the second argument of {\lstinline|_∸_|} is \textit{contravariant} in the sense
that the result of {\lstinline|_∸_|} would increase when the second argument decreases.

Even worse, the function that takes the substitute as an argument may not
be even be \textit{monotonic} as monus. As a result, a generic mechanism like
{\lstinline|cong|} does not exist in preorder reasoning. We can only substitute
part of an expression when the function is \textit{monotonic}.


%
% Similar to that of equation reasoning, sometimes we need to rewrite expressions with
% {\lstinline|_≈⟨_⟩_|} when they are equal to each other (An equivalence relation is also a
% preorder). We would also skip these steps.
%
% Some of the obvious transitive steps (that is written in {\lstinline|_≤⟨_⟩_|})
% will also be skipped.

\subsection{Dispense with trivial proofs}

From now on, we will dispense with most of the steps and justifications in
reasonings, because it is often obvious to see what happened in the process.

In fact, there are is no formal distinction between the proofs we disregard and
those we feel important. They are all equally indispensable to Agda.

\subsection{Relevant Properties of Natural Numbers}

Properties of natural numbers play a big role in the development of proofs in
this thesis. In this section, we will introduce various relevant properties of
{\lstinline|ℕ|}. Most of the basic properties listed here (such as the ones demonstrated above)
are taken from the stantard library while others are just lemmata or corollaries of
these theorems.
\footnote{\textit{Theorem}, \textit{lemma}, \textit{corollary} and \textit{property}
are all synonyms for \textit{established proposition}. There are no formal
distinction between these terms and they are used exchangeably in the thesis.}

\paragraph{addition}

\begin{itemize}
    \item {\lstinline|+-assoc : ∀ m n o → (m + n) + o ≡ m + (n + o)|}
        \\ the associative property of addition.
    \item {\lstinline|+-right-identity : ∀ n → n + 0 ≡ n|}
        \\ the right identity of addition.
    \item {\lstinline|+-suc : ∀ m n → m + suc n ≡ suc (m + n)|}
        \\ moving {\lstinline|suc|} from one term to another.
    \item {\lstinline|+-comm : ∀ m n → m + n ≡ n + m|}
        \\ the commutative property of addition.
    \item {\lstinline|cancel-+-left : ∀ i {j k} → i + j ≡ i + k → j ≡ k|}
        \\ the left cancellation property of addition.
    \item {\lstinline|cancel-+-right : ∀ k {i j} → i + k ≡ j + k → i ≡ j|}
        \\ the right cancellation property of addition.
\end{itemize}

\paragraph{multiplication}

\begin{itemize}
    \item {\lstinline|+-*-suc : ∀ m n → m * suc n ≡ m + m * n|}
        \\ multiplication over {\lstinline|suc|}.
    \item {\lstinline|*-right-zero : ∀ n → n * 0 ≡ 0|}
        \\ the right absorbing element of multiplication.
    \item {\lstinline|*-comm : ∀ m n → m * n ≡ n * m|}
        \\ the commutative property of multiplication.
    \item {\lstinline|distribʳ-*-+ : ∀ m n o → (n + o) * m ≡ n * m + o * m|}
        \\ the right distributive property of multiplication over addition.
\end{itemize}

\paragraph{join and meet}


\paragraph{monotonicity of operations}

\end{document}
