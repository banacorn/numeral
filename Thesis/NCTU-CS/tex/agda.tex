\providecommand{\main}{..}
\documentclass[\main/thesis.tex]{subfiles}
\begin{document}

\chapter{A gentle introduction to dependently typed programming in Agda}\label{agda}

There are already plenty of tutorials and introductions of Agda
\cite{norell2009dependently}\cite{FLOLAC16DTP}\cite{brutal}.
We will nonetheless compile a simple and self-contained tutorial from the
materials cited above, covering the parts (and only the parts) we need in this thesis.

Some of the more advanced constructions (such as views and universes) will not
be introduced in this chapter, but in other places where we need them.

\paragraph{Remark}
We assume that readers have some basic understanding of Haskell. Readers who are
familiar with Agda and dependently typed programming may skip this chapter.

\section{Some basics}


Agda is a \textit{dependently typed functional programming language} and also an
\textit{interactive proof assistant}. This language can serve both purposes because
it is based on \textit{Martin-Löf type theory}\cite{martin1984intuitionistic},
hence the Curry-Howard correspondence\cite{sorensen2006lectures},
which states that: ``propositions are types'' and ``proofs are programs.''
In other words, proving theorems and writing programs are essentially the same.
In Agda we are free to interchange between these two interpretations.
The current version (Agda2) is a completely rewrite by Ulf Norell during his
Ph.D. at Chalmers University of Technology.

We say that Agda is interactive because theorem proving involves a lot of
conversations between the programmer and the type checker.
Moreover, it is often difficult, if not impossible, to develop and prove a theorem at one stroke.
Just like programming, the process is incremental.
So Agda allows us to leave some ``holes'' in a program, refine them gradually, and
complete the proofs ``hole by hole''.

Take this half-finished function definition for example.

\begin{lstlisting}
is-zero : ℕ → Bool
is-zero x = ?
\end{lstlisting}

We can leave out the right-hand side and ask:
``what's the type of the goal?'', ``what's the context of this case?'', etc.
Agda would reply us with:

\begin{lstlisting}
GOAL : Bool
x : ℕ
\end{lstlisting}

Next, we may ask Agda to pattern match on {\lstinline|x|} and rewrite the program for us:

\begin{lstlisting}
is-zero : ℕ → Bool
is-zero zero    = ?
is-zero (suc x) = ?
\end{lstlisting}

We could fulfill these goals by giving an answer,
or even ask Agda to solve the problem (by pure guessing) for us if it is not too difficult.

\begin{lstlisting}
is-zero : Int → Bool
is-zero zero    = true
is-zero (suc x) = false
\end{lstlisting}

After all of the goals have been accomplished and type-checked,
we consider the program to be finished.
Often, there is not much point in running an Agda program,
because it is mostly about compile-time static constructions.
This is what programming and proving things looks like in Agda.

\section{Simply typed programming in Agda}

Since Agda was heavily influenced by Haskell, simply typed programming in Agda
is similar to that in Haskell.

\paragraph{Datatypes}


Unlike in other programming languages, there are no ``built-in''
datatypes such as \textit{Int}, \textit{String}, or \textit{Bool}.
The reason is that they can all be created out of thin air, so why
bother having them predefined?

Datatypes are introduced with {\lstinline|data|} declarations.
Here is a classical example, the type of booleans.

\begin{lstlisting}
data Bool : Set where
    true  : Bool
    false : Bool
\end{lstlisting}

This declaration brings the name of the datatype ({\lstinline|Bool|})
and its constructors ({\lstinline|true|} and {\lstinline|false|}) into scope.
The notation allow us to explicitly specify the types of these newly introduced
entities.

\begin{enumerate}
    \item {\lstinline|Bool|} has type {\lstinline|Set|}\footnote{{\lstinline|Set|} is the type of small types, and {\lstinline|Set₁|} is the type
of {\lstinline|Set|}, and so on. They form a hierarchy of types.}
    \item {\lstinline|true|} has type {\lstinline|Bool|}
    \item {\lstinline|false|} has type {\lstinline|Bool|}
\end{enumerate}

\paragraph{Pattern matching}

Similar to Haskell, datatypes are eliminated by pattern matching.
Here is a function that pattern matches on {\lstinline|Bool|}.

\begin{lstlisting}
not : Bool → Bool
not true  = false
not false = true
\end{lstlisting}

Agda is a \textit{total} language,
which means that partial functions are not valid constructions.
Programmers are obliged to convince Agda that a program terminates and does not
crash on all possible inputs.
The following example will not be accepted by the termination checker because the
case {\lstinline|false|} is missing.

\begin{lstlisting}
not : Bool → Bool
not true  = false
\end{lstlisting}

\paragraph{Inductive datatype} Let us move on to a more interesting datatype with
an inductive definition. Here is the type of natural numbers.

\begin{lstlisting}
data ℕ : Set where
    zero : ℕ
    suc : ℕ → ℕ
\end{lstlisting}

The decimal number ``4'' is represented as {\lstinline|suc (suc (suc (suc zero)))|}.
Agda also accepts decimal literals if the datatype {\lstinline|ℕ|} complies with
certain language pragma.

Addition on {\lstinline|ℕ|} can be defined as a recursive function.

\begin{lstlisting}
_+_ : ℕ → ℕ → ℕ
zero  + y = y
suc x + y = suc (x + y)
\end{lstlisting}

We define {\lstinline|_+_|} by pattern matching on the first argument, which results
in two cases: the base case, and the inductive step. We are allowed to make
recursive calls, as long as the type checker is convinced that the function
would terminate.

Those underlines surrounding {\lstinline|_+_|} act as placeholders for arguments, making
it an infix function in this instance.

\paragraph{Dependent functions and type arguments}

Up till now, everything looks much the same as in Haskell, but a problem arises as
we move on to defining something that needs more power of abstraction. Take identity
functions for example:

\begin{lstlisting}
id-Bool : Bool → Bool
id-Bool x = x

id-ℕ : ℕ → ℕ
id-ℕ x = x
\end{lstlisting}

In order to define a more general identity function, those concrete types need
to be abstracted away. That is, we need \textit{parametric polymorphism}, and this is
where dependent types come into play.

A dependent type is a type whose definition may depend on a value. A dependent
function is a function whose type may depend on a value of its arguments.

In Agda, function types are denoted as:

\begin{lstlisting}
A → B
\end{lstlisting}
%
where {\lstinline|A|} is the type of domain and {\lstinline|B|} is the type of
codomain. To let {\lstinline|B|} depends on the value of {\lstinline|A|}, the
value has to \textit{named}. In Agda we write:

\begin{lstlisting}
(x : A) → B x
\end{lstlisting}

The value of {\lstinline|A|} is named {\lstinline|x|} and then fed to {\lstinline|B|}.
As a matter of fact, {\lstinline|A → B|} is just a syntax sugar for {\lstinline|(_ : A) → B|}
with the name of the value being irrelevant. The underline {\lstinline|_|} here
means ``I don't bother naming it''.

Back to our identity function, if {\lstinline|A|} happens to be {\lstinline|Set|},
the type of all small types, and the result type happens to be solely {\lstinline|x|}:

\begin{lstlisting}
(x : Set) → x
\end{lstlisting}

Voila, we have polymorphism, and thus the identity function can now be defined as:

\begin{lstlisting}
id : (A : Set) → A → A
id A x = x
\end{lstlisting}

{\lstinline|id|} now takes an extra argument, the type of the second argument.
{\lstinline|id Bool true|} evaluates to {\lstinline|true|}.

\paragraph{Implicit arguments}

We have implemented an identity function and seen how polymorphism can be modeled
with dependent types. However, the additional argument that the identity function
takes is rather unnecessary, since its value can always be determined by looking
at the type of the second argument.

Fortunately, Agda supports \textit{implicit arguments}, a syntax sugar that could
save us the trouble of having to spell them out. Implicit arguments are enclosed
in curly brackets in the type expression. We are free to dispense with these arguments
when their values are irrelevant to the definition.

\begin{lstlisting}
id : {A : Set} → A → A
id x = x
\end{lstlisting}

Or when the type checker can figure them out on function application.

\begin{lstlisting}
val : Bool
val = id true
\end{lstlisting}

Any arguments can be made implicit, but it does not imply that values of
implicit arguments can always be inferred or derived from context. We can always
make them implicit arguments explicit on application:

\begin{lstlisting}
val : Bool
val = id {Bool} true
\end{lstlisting}

Or when they are relevant to the definition:

\begin{lstlisting}
silly-not : {_ : Bool} → Bool
silly-not {true}  = false
silly-not {false} = true
\end{lstlisting}

\paragraph{More syntax sugars}

We could skip arrows between arguments in parentheses or braces:

\begin{lstlisting}
id : {A : Set} (a : A) → A
id {A} x = x
\end{lstlisting}

Also, there is a shorthand for merging names of arguments of the same type, implicit or not:

\begin{lstlisting}
const : {A B : Set} → A → B → A
const a _ = a
\end{lstlisting}

Sometimes when the type of some value can be inferred, we could either replace
the type with an underscore, say {\lstinline|(A : _)|}, or we could write it as
{\lstinline|∀ A|}. For the implicit counterpart, {\lstinline|{A : _}|} can be
written as {\lstinline|∀ {A}|}.

\paragraph{Parameterized Datatypes}


Just as functions can be polymorphic, datatypes can be parameterized by other
types, too. The datatype of lists is defined as follows:

\begin{lstlisting}
data List (A : Set) : Set where
    []  : List A
    _∷_ : A → List A → List A
\end{lstlisting}

The scope of the parameters spreads over the entire declaration so that they can
appear in the constructors.
Here are the types of the datatype and its constructors.

\begin{lstlisting}
infixr 5 _∷_

[] : {A : Set} → List A
_∷_ : {A : Set} → A → List A → List A
List : Set → Set
\end{lstlisting}
%
where {\lstinline|A|} can be anything, even {\lstinline|List (List (List Bool))|},
as long as it is of type {\lstinline|Set|}. {\lstinline|infixr|} specifies the
precedence of the operator {\lstinline|_∷_|}.

\paragraph{Indexed Datatypes}


% Indexed datatypes, or inductive families, allow us to not only

{\lstinline|Vec|} is a datatype that is similar to {\lstinline|List|}, but more
powerful, in that it encodes not only the type of its element but also its
length.

\begin{lstlisting}
data Vec (A : Set) : ℕ → Set where
    []  : Vec A zero
    _∷_ : {n : ℕ} → A → Vec A n → Vec A (suc n)
\end{lstlisting}

{\lstinline|Vec A n|} is a vector of values of type {\lstinline|A|} and
has the length of {\lstinline|n|}. Here are some of its inhabitants:

\begin{lstlisting}
nil : Vec Bool zero
nil = []

vec : Vec Bool (suc (suc zero))
vec = true ∷ false ∷ []
\end{lstlisting}

We say that {\lstinline|Vec|} is \textit{parameterized} by a type of {\lstinline|Set|}
and is \textit{indexed} by values of {\lstinline|ℕ|}.
We distinguish indices from parameters. However, it is not obvious how they are
different by looking at the declaration.

Parameters are \textit{parametric}, in the sense that, they have no effect on the ``shape'' of a datatype.
The choice of parameters only effects which kind of values are placed there.
Pattern matching on parameters does not reveal any insights into their whereabouts.
Because they are \textit{uniform} across all constructors, one can always replace
the value of a parameter with another one of the same type.

On the other hand, indices may affect which inhabitants are allowed in the
datatype. Different constructors may have different indices. In that case, pattern
matching on indices may yield relevant information about their constructors.

For example, given a term whose type is {\lstinline|Vec Bool zero|},
then we are certain that the constructor must be {\lstinline|[]|},
and if the type is {\lstinline|Vec Bool (suc n)|} for some {\lstinline|n|},
then the constructor must be {\lstinline|_∷_|}.

We could, for instance, define a {\lstinline|head|} function that cannot crash.

\begin{lstlisting}
head : ∀ {A n} → Vec A (suc n) → A
head (x ∷ xs) = x
\end{lstlisting}

As a side note, parameters can be thought as a degenerate case of indices whose
distribution of values is uniform across all constructors.

\paragraph{With abstraction}


Say, we want to define {\lstinline|filter|} on {\lstinline|List|}:

\begin{lstlisting}
filter : ∀ {A} → (A → Bool) → List A → List A
filter p [] = []
filter p (x ∷ xs) = ?
\end{lstlisting}

We are stuck here because the result of {\lstinline|p x|} is only available at
runtime. Fortunately, with abstraction allows us to pattern match on the result
of an intermediate computation by adding the result as an extra argument on the
left-hand side:

\begin{lstlisting}
filter : ∀ {A} → (A → Bool) → List A → List A
filter p [] = []
filter p (x ∷ xs) with f x
filter p (x ∷ xs) | true  = x ∷ filter p xs
filter p (x ∷ xs) | false = filter p xs
\end{lstlisting}

\paragraph{Absurd patterns}

The \textit{unit type}, or \textit{top}, is a datatype inhabited by
exactly one value, denoted {\lstinline|tt|}.

\begin{lstlisting}
data ⊤ : Set where
    tt : ⊤
\end{lstlisting}

The \textit{empty type}, or \textit{bottom}, on the other hand, is a datatype
that is inhabited by nothing at all.

\begin{lstlisting}
data ⊥ : Set where
\end{lstlisting}

These types seem useless, and without constructors, it is impossible to
construct an instance of {\lstinline|⊥|}. What is an type that cannot be
constructed good for?

Say, we want to define a safe {\lstinline|head|} on {\lstinline|List|} that
does not crash on any inputs. Naturally, in a language like Haskell,
we would come up with a predicate like this to filter out empty lists
{\lstinline|[]|} before passing them to {\lstinline|head|}.

\begin{lstlisting}
non-empty : ∀ {A} → List A → Bool
non-empty []       = false
non-empty (x ∷ xs) = true
\end{lstlisting}

The predicate only works at runtime. It is impossible for the type
checker to determine whether the input is empty or not at compile time.

However, things are quite different quite in Agda. With \textit{top} and \textit{bottom},
we could do some tricks on the predicate, making it returns a \textit{Set}, rather
than a \textit{Bool}!

\begin{lstlisting}
non-empty : ∀ {A} → List A → Set
non-empty []       = ⊥
non-empty (x ∷ xs) = ⊤
\end{lstlisting}

Notice that now this predicate is returning a type. So we can use it in the type
expression. {\lstinline|head|} can thus be defined as:

\begin{lstlisting}
head : ∀ {A} → (xs : List A) → non-empty xs → A
head []       proof = ?
head (x ∷ xs) proof = x
\end{lstlisting}

In the {\lstinline|(x ∷ xs)|} case, the argument {\lstinline|proof|} would
have type {\lstinline|⊤|}, and the right-hand side is simply {\lstinline|x|};
in the {\lstinline|[]|} case, the argument {\lstinline|proof|} would
have type {\lstinline|⊥|}, but what should be returned at the right-hand side?

It turns out that, the right-hand side of the {\lstinline|[]|} case would be the
least thing to worry about because it is completely impossible to have such a case.
Recall that {\lstinline|⊥|} has no inhabitants, so if a case has an argument of
that type, it is too good to be true.

Type inhabitance is, in general, an undecidable problem.
However, when pattern matching on a type that is obviously empty (such as {\lstinline|⊥|}),
Agda allows us to drop the right-hand side and eliminate the argument with {\lstinline|()|}.

\begin{lstlisting}
head : ∀ {A} → (xs : List A) → non-empty xs → A
head []       ()
head (x ∷ xs) proof = x
\end{lstlisting}

Whenever {\lstinline|head|} is applied to some list {\lstinline|xs|},
the programmer is obliged to convince Agda that {\lstinline|non-empty xs|}
reduces to {\lstinline|⊤|},
which is only possible when {\lstinline|xs|} is not an empty list.
On the other hand, applying an empty list to {\lstinline|head|} would result in
a function of type {\lstinline|head [] : ⊥ → A|} which is impossible to
be fulfilled.

\paragraph{Propositions as types, proofs as programs}

The previous paragraphs are mostly about the \textit{programming}
aspect of the language, but there is another aspect to it.
Recall the Curry–Howard correspondence, propositions are types and proofs are
programs. A proof exists for a proposition the way that a value inhabits a type.

{\lstinline|non-empty xs|} is a type, but it can also be thought of as a
proposition stating that {\lstinline|xs|} is not empty.
When {\lstinline|non-empty xs|} evaluates to {\lstinline|⊥|}, no value inhabits
{\lstinline|⊥|}, which means no proof exists for the proposition {\lstinline|⊥|};
when {\lstinline|non-empty xs|} evaluates to {\lstinline|⊤|}, {\lstinline|tt|}
inhabits {\lstinline|⊥|}, a trivial proof exists for the proposition {\lstinline|⊤|}.

In intuitionistic logic, a proposition is considered to be ``true'' when it is
inhabited by a proof, and considered to be ``false'' when there exists no proof.
Contrary to classical logic, where every propositions are assigned one of two truth values.
We can see that {\lstinline|⊤|} and {\lstinline|⊥|} corresponds to \textit{true}
and \textit{false} in this sense.

Negation is defined as a function from a proposition to {\lstinline|⊥|}.

\begin{lstlisting}
¬ : Set → Set
¬ P = P → ⊥
\end{lstlisting}

We could exploit {\lstinline|⊥|} further to deploy the principle of explosion
of intuitionistic logic, which states that: ``from falsehood, anything (follows)''
(Latin: \textit{ex falso (sequitur) quodlibet}).

\begin{lstlisting}
⊥-elim : ∀ {Whatever : Set} → ⊥ → Whatever
⊥-elim ()
\end{lstlisting}


\paragraph{Decidable propositions}

A proposition is decidable when it can be proved \textit{or} disapproved.
\footnote{The connective \textit{or} here is not a disjunction in the classical sense.
Either way, a proof or a disproval has to be given.}

\begin{lstlisting}
data Dec (P : Set) : Set where
    yes :   P → Dec P
    no  : ¬ P → Dec P
\end{lstlisting}

{\lstinline|Dec|} is very similar to its two-valued cousin {\lstinline|Bool|},
but way more powerful, because it also explains (with a proof) why a proposition
holds or why it does not.

Suppose we want to know if a natural number is even or odd. We know that {\lstinline|zero|}
is an even number, and if a number is even then its successor's successor is even as well.

\begin{lstlisting}
    data Even : ℕ → Set where
        base : Even zero
        step : ∀ {n} → Even n → Even (suc (suc n))
\end{lstlisting}

We need the opposite of {\lstinline|step|} as a lemma as well.

\begin{lstlisting}
    2-steps-back : ∀ {n} → ¬ (Even n) → ¬ (Even (suc (suc n)))
    2-steps-back ¬p q = ?
\end{lstlisting}

{\lstinline|2-steps-back|} takes two arguments instead of one because the return
type {\lstinline|¬ (Even (suc (suc n)))|} is actually a synonym of
{\lstinline|Even (suc (suc n)) → ⊥|}. Pattern matching on the second argument
of type {\lstinline|Even (suc (suc n))|} further reveals that it could only be
constructed by {\lstinline|step|}.  By contradicting {\lstinline|¬p : ¬ (Even n)|}
and {\lstinline|p : Even n|}, we complete the proof of this lemma.

\begin{lstlisting}
    contradiction : ∀ {P Whatever : Set} → P → ¬ P → Whatever
    contradiction p ¬p = ⊥-elim (¬p p)

    two-steps-back : ∀ {n} → ¬ (Even n) → ¬ (Even (suc (suc n)))
    two-steps-back ¬p (step p) = contradiction p ¬p
\end{lstlisting}

Finally, {\lstinline|Even?|} determines a number be even by induction on its
predecessor's predecessor. {\lstinline|step|} and {\lstinline|two-steps-back|}
can be viewed as functions that transform proofs.

\begin{lstlisting}
    Even? : (n : ℕ) → Dec (Even n)
    Even? zero          = yes base
    Even? (suc zero)    = no (λ ())
    Even? (suc (suc n)) with Even? n
    Even? (suc (suc n)) | yes p = yes (step p)
    Even? (suc (suc n)) | no ¬p = no  (two-steps-back ¬p)
\end{lstlisting}

The syntax of {\lstinline|λ ()|} looks weird, as the result of contracting
an argument of type {\lstinline|⊥|} of a lambda expression {\lstinline|λ x → ?|}.
It is a convention to suffix a decidable function's name with {\lstinline|?|}.

\paragraph{Propositional equality}

Saying that two things are ``equal'' is a notoriously intricate topic in type theory.
There are many different notions of equality \cite{equality}.
We will not go into each kind of equalities in depth but only skim through those exist in Agda.

\textit{Definitional equality}, or \textit{intensional equality} is simply a
synonym, a relation between linguistic expressions. It is a primitive judgement
of the system, stating that two things are the same to the type checker
\textbf{by definition}.

\textit{Computational equality} is a slightly more powerful notion.
Two programs are consider equal if they compute (beta-reduce) to the same value.
For example, {\lstinline|1 + 1|} and {\lstinline|2|} are equal in Agda in this notion.

However, expressions such as {\lstinline|a + b|} and {\lstinline|b + a|} are not
considered equal by Agda, neither \textit{definitionally} nor \textit{computationally},
because there are simply no rules in Agda saying so.

{\lstinline|a + b|} and {\lstinline|b + a|} are only \textit{extensionally equal}
in the sense that, given \textbf{any} pair of numbers, say {\lstinline|1|} and {\lstinline|2|},
Agda can see that {\lstinline|1 + 2|} and {\lstinline|2 + 1|} are computationally equal.
But when it comes to \textbf{every} pair of numbers, Agda fails to justify that.

We could convince Agda about the fact that {\lstinline|a + b|} and {\lstinline|b + a|}
are equal for every pair of {\lstinline|a|} and {\lstinline|b|} by encoding this
theorem in a \textit{proposition} and then prove that the proposition holds.
This kind of proposition can be expressed with \textit{identity types}.

\begin{lstlisting}
data _≡_ {A : Set} (x : A) : A → Set where
    refl : x ≡ x
\end{lstlisting}

This inductive datatype says that: for all {\lstinline|a b : A|},
if {\lstinline|a|} and {\lstinline|b|} are \textit{computationally equal},
that is, both computes to the same value,
then {\lstinline|refl|} is a proof of {\lstinline|a ≡ b|},
and we say that {\lstinline|a|} and {\lstinline|b|} are \textit{propositionally equal}!

{\lstinline|_≡_|} is an equivalence relation. It means that {\lstinline|_≡_|}
is \textit{reflexive} (by definition), \textit{symmetric} and \textit{transitive}.

\begin{lstlisting}
sym : {A : Set} {a b : A} → a ≡ b → b ≡ a
sym refl = refl

trans : {A : Set} {a b c : A} → a ≡ b → b ≡ c → a ≡ c
trans refl refl = refl
\end{lstlisting}

{\lstinline|_≡_|} is congruent, meaning that we could \textbf{substitute equals for equals}.

\begin{lstlisting}
cong : {A B : Set} {a b : A} → (f : A → B) → a ≡ b → f a ≡ f b
cong f refl = refl
\end{lstlisting}

Although these {\lstinline|refl|}s look all the same at term level,
they are proofs of different propositional equalities.

\paragraph{Dotted patterns}

Consider an alternative version of {\lstinline|sym|} on {\lstinline|ℕ|}.

\begin{lstlisting}
sym' : (a b : ℕ) → a ≡ b → b ≡ a
sym' a b eq = ?
\end{lstlisting}
%
where {\lstinline|eq|} has type {\lstinline|a ≡ b|}.
If we pattern match on {\lstinline|eq|} then Agda would rewrite {\lstinline|b|}
as {\lstinline|.a|} and the goal type becomes {\lstinline|a ≡ a|}.
\begin{lstlisting}
sym' : (a .a : ℕ) → a ≡ a → a ≡ a
sym' a .a refl = ?
\end{lstlisting}

What happened under the hood is that {\lstinline|a|} and {\lstinline|b|} are
\textit{unified} as the same thing. The second argument is dotted to signify that
it is \textit{constrained} by the first argument {\lstinline|a|}. {\lstinline|a|}
becomes the only argument available for further binding or pattern matching.

\paragraph{Standard library}

It would be inconvenient if we have to construct everything we need from scratch.
Luckily, the community has maintained a standard library that comes with many useful
and common constructions.

The standard library is not ``chartered'' by the compiler or the type checker,
there's simply nothing special about it. We may as well as roll our own library.
\footnote{Some primitives that require special treatments, such as IO, are taken
care of by language pragmas provided by Agda.}

\end{document}
