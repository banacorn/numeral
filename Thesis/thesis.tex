
\title{Generalizing Positional Numeral Systems}
\author{
    Luā Tîng-Giān
}
\date{\today}

\documentclass[12pt, a4paper]{article}
% \linespread{1.5}

% for unicode symbols
\usepackage{fontspec}
\setmonofont{DejaVu Sans Mono}

% for maths symbols
\usepackage{mathtools}
\usepackage{bm}


% for CJK
\usepackage{xeCJK}

\usepackage{color}
\definecolor{light-gray}{gray}{0.95}

\usepackage{listings}
\lstset{ %
  basicstyle=\ttfamily\footnotesize,              % the size of the fonts that are used for the code
  backgroundcolor=\color{light-gray},
  xleftmargin=0.5cm,
  frame=tlbr,
  framesep=10pt,
  framerule=0pt
}

\begin{document}
\maketitle

\begin{abstract}
% Abstact [draft]
Numbers are everywhere in our daily lives, and positional numeral systems are
arguably the most important and common representation of numbers. In this work
we have constructed a generalized positional numeral system in Agda to model many
of these representations, and investigate some of their properties and relationship
with the classical unary representation of the natural numbers.

% TODO: maybe say more about that predicate universe stuff
\end{abstract}

\section{Introduction}

\subsection{Positional numeral systems}\label{num}
% [draft]

A numeral system is a writing system for expressing numbers, and humans have
invented various kinds of numeral systems throughout history. Most of the
systems we are using today are positional notations\cite{knuth1998art} because
they can express \textbf{infinite} numbers with just a \textbf{finite} set of
symbols so-called \textit{digits}.

A positional numeral systems represents a number by adding up a series of digits
of different orders of magnitude. Take a common decimal number for example:

$$ (2016)_{10} = 2\times10^3 + 0\times10^2 + 1\times10^1 + 6\times10^0 $$

\subsubsection{Symtems of different bases}

These numeral systems can take on different \textit{bases}. The ubiquitous decimal
numeral system as we know, has the base of 10. While the binaries that can be found
in our machines nowadays has the base of 2. That already trivial formula can
be generalized a bit to represent numbers of different bases.

$$
    ({...d_3d_2d_1d_0})_{base}
    =
    ... + d_3\times base^3 + d_2\times base^2 + d_1\times base^1 + d_0\times base^0
$$

Where $ d_{n} $ is a digit that ranges from $ 0 $ to $ base - 1 $ for all $ n $.


\subsubsection{Digits of different ranges}

Some computer scientists and mathematicians seem to be more comfortable with
unary (base-1) numbers because they are isomorphic to the natural numbers à la Peano.


$$
    (1111)_{1} \cong
        \overbrace{\text{suc (suc (suc (suc}}^4 + \text{ zero)))}
$$

Statements established on such numbers can be proven using mathematical
induction. And people have implemented and proven a great deal of functions and
properties on these unary numbers because they are easy to work with.

But the formula we've just put down for evaluating positional numeral systems
doesn't work for unary numbers, as it requires the digits to range from $ 0 $ to
$ base - 1 $. That is, the only digit has to be $ 0 $, yet the only digit unary
numbers have is $ 1 $.

To evaluate unary numbers, we need to relax the constraint on the range of digits
by introducing a new variable, \textit{offset}:

$$
    ({...d_3d_2d_1d_0})_{base}
    =
    ... + d_3\times base^3 + d_2\times base^2 + d_1\times base^1 + d_0\times base^0
$$

Where $ d_{n} $ ranges from \textit{offset} to \textit{offset + base - 1} for
all $ n $. Now that in our model, unary numbers would have an offset of $ 1 $,
and systems of other bases would have offsets of $ 0 $.

\subsubsection{Numerical representation}

% Besides from isomorphic to natural numbers

One may notice that the structure of unary numbers also looks suspiciously similar
to that of lists'. Let's compare their definition in Haskell.

% use minipage for juxtaposing two blocks of codes
\noindent\begin{minipage}{.45\textwidth}
\begin{lstlisting}
data Nat = Zero
         | Suc Nat
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{.48\textwidth}
\begin{lstlisting}
data List a = Nil
            | Cons a (List a)
\end{lstlisting}
\end{minipage}

If we replace every {\lstinline|Cons _|} with {\lstinline|Suc|} and {\lstinline|Nil|}
with {\lstinline|Zero|}, then a list becomes an unary number.
And that's exactly what the {\lstinline|length|} function,
a homomorphism from lists to unary numbers, does.

Now let's compare addition on unary number and merge (append) on lists:

\noindent\begin{minipage}{.48\textwidth}
\begin{lstlisting}[basicstyle=\ttfamily\scriptsize]
add : Nat → Nat → Nat
add Zero    y = y
add (Suc x) y =
    Suc (add x y)
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{.45\textwidth}
\begin{lstlisting}[basicstyle=\ttfamily\scriptsize]
append : List a → List a → List a
append Nil         ys = ys
append (Cons x xs) ys =
    Cons x (append xs ys)
\end{lstlisting}
\end{minipage}

Aside from having virtually identical implementations, operations on unary numbers
and lists both have the same time complexity. Incrementing a unary number takes
$ O(1) $, inserting an element into a list also takes $ O(1) $; adding two unary
numbers takes $ O(n) $, appending a list to another also takes $ O(n) $.

And if we look at implementations and operations of binary numbers and binomial
heaps, the resemblances are also uncanny.

[insert some images here]

The strong anology between positional numeral systems and certain data structures
suggests that, numeral systems can used as templates for designing containers.
Such data structures are called \textbf{Numerical Representations}\cite{okasaki1996purely}
\cite{hinze1998numerical}.

\subsubsection{Redundancy}

There are actually more than one way to represent the number $ 2016 $ in decimal.
This can be achieved simply by adding leading zeros.

$$
    02016, 002016, 0002016, 0002016, ...
$$


Such a numeral system is said to be \textit{redundant}.

So far the numeral systems we are concerning all have exactly \textit{base} digits,
ranging from \textit{offset} to \textit{offset + base - 1}.


% But there are numerical representations out there that still doesn't

% There's a strong anology between positional numeral systems and certain containers
% , such data structures are called \textbf{Numerical Representation}.

%
% $$ 1111_{1} = 1\times 1^3 + 1\times 1^2 + 1\times 1^1 + 1\times 1^0 = 4_{10} $$



% --, which is no harder than counting pebbles.



% system used in our daily lives is the
% base-10 (decimal) system,


% While the most ubiquitous positional notation used in our daily lives is the
% base-10 (decimal) system, and binary (base-2) numbers can be found in almost all
% digital circuits. Some computer scientists and mathematicians seem to be more
% comfortable with unary (base-1) numbers, which is no harder than counting pebbles.
%
% Natural numbers (à la Peano) are defined in a way that is isomorphic to unary
% numbers. Statements established on such numbers can be proven using mathematical
% induction. And people have implemented and proven a great deal of functions and
% properties on these unary numbers because they are easy to work with.
%
% But that simplicity comes at a cost, the time complexity of functions defined on
% unary numbers is significantly

%
% Natural numbers (à la Peano) are defined in a way that is isomorphic to unary
% numbers. Statements established on such numbers can be proven using mathematical
% induction, an essential proving technique.
% %  which can then be generalized to all
% % kinds of well-founded structures, known as structural induction.
%
% People have implemented and proven a great deal of functions and properties on
% these unary numbers because they are easy to work with. But the simplicity comes
% at a cost, the time complexity of functions defined on unary numbers is significantly
% higher than those defined on systems of other bases, say, binary numbers. Hence,
% it's not practical in doing heavy calculations.


% The \textit{numbers} we will be constructing in this work are the \textit{natural numbers}.
% And before


% The \textit{numbers} we are constructing in this work are the \textit{natural numbers}.
% We learned how to count with these numbers when we are little. But what are numbers, really?

% \paragraph{Recursive}

% Paul Benacerraf once argued\cite{benacerraf1965numbers} that, there are two kinds
% of \textit{counting} which corresponds to \textbf{transitive} and \textbf{intransitive}
% uses of the verb "to count". Transitive counting, in his sense, is to assign one
% of the numbers to the cardinality of a set, by establish a one-to-one correspondence
% between the numbers and the objects one is counting, all the way from none to
% all. Intransitive counting, on the other hand, is to generate a sequence of
% notation, that could go as far as we need. And it seems that one can only learn
% how to count intransitively first, before knowning how to count transitively,
% but not vice versa.
%
% He further discussed that the numbers must be at least recursive

% \paragraph{Numbers are recursive}
%
% \paragraph{Internal definition is immaterial}

% \subsection{Positional numeral systems}\label{pos}
%
% A numeral system is a writing system for expressing numbers, and humans have
% invented various kinds of numeral systems throughout history. Most of the
% systems we are using today are positional notations because they can express
% \textbf{infinite} numbers with just a \textbf{finite} set of symbols.
%
% While the most ubiquitous positional notation used in our daily lives is the
% base-10 (decimal) system, and binary (base-2) numbers can be found in almost all
% digital circuits. Some computer scientists and mathematicians seem to be more
% comfortable with unary (base-1) numbers, which is no harder than counting pebbles.
%
% Natural numbers (à la Peano) are defined in a way that is isomorphic to unary
% numbers. Statements established on such numbers can be proven using mathematical
% induction, an essential proving technique.
% %  which can then be generalized to all
% % kinds of well-founded structures, known as structural induction.
%
% People have implemented and proven a great deal of functions and properties on
% these unary numbers because they are easy to work with. But the simplicity comes
% at a cost, the time complexity of functions defined on unary numbers is significantly
% higher than those defined on systems of other bases, say, binary numbers. Hence,
% it's not practical in doing heavy calculations.

\paragraph{Outline}
The remainder of the thesis is organized as follows.
% Section~\ref{agda} gives account of previous work.

\section{A gental introduction to dependently typed programming in Agda}\label{agda}
% [draft]

There are already plenty of tutorials and introductions of Agda\cite{norell2009dependently}\cite{FLOLAC16DTP}\cite{brutal}.
We will nonetheless compile a simple and self-contained tutorial from the
materials cited above, covering the part (and only the part) we need in this work.

Some of the more advenced constructions (such as views and universes) used in
the following sections will be introduced along the way.

We assume that all readers have some basic understanding of Haskell, and those
who are familiar with Agda and dependently typed programming may skip this chapter.

\subsection{Some basics}
% [draft]
Agda is a dependently typed functional programming language based on
\textbf{Martin-Löf type theory} \cite{martin1984intuitionistic}.
The first version of Agda was originally developed by Catarina Coquand at Chalmers
University of Technology, the current version (Agda2) is a completely rewrite by
Ulf Norell during his PhD at Chalmers.

Agda is also an interactive theorem prover. Because proving theorems involves a
lot of conversations between the programmer and the type checker. Just like programming,
the process is incremental. It is difficult, if not impossible, to develop and
prove a theorom at one stroke. Agda allows us to leave some "holes" in a
program, refine them gradually, and complete your proofs "hole by hole".

Take this unfininshed function definition for instance, we could leave out the
right-hand side.

\begin{lstlisting}
is-zero : Int → Bool
is-zero x = ?
\end{lstlisting}

In practice, we may ask, for example, "what's the type of the goal?",
 "what's the context of this case?", etc. And Agda would reply us with:

\begin{lstlisting}
GOAL : Bool
x : Int
\end{lstlisting}

Then we might ask Agda to pattern match on {\lstinline|x|} and rewrite the program for us:

\begin{lstlisting}
is-zero : Int → Bool
is-zero zero    = ?
is-zero (suc x) = ?
\end{lstlisting}

This is basically what pragramming and proving things looks like in Agda.

\subsection{Simply typed programming in Agda}

\paragraph{In the beginning there was nothing}
% [draft]
Unlike in other programming languages, there are no "built-in"
datatypes such as \textit{Int}, \textit{String}, or \textit{Bool}.
The reason is that they can all be created out of thin air, so why bother?

\paragraph{Let there be datatype}
% [draft]
Datatypes are introduced with {\lstinline|data|} declarations. Here is a classical example, the type of booleans.

\begin{lstlisting}
data Bool : Set where
    true  : Bool
    false : Bool
\end{lstlisting}

The name of the datatype ({\lstinline|Bool|}) and its constructors ({\lstinline|true|} and {\lstinline|false|}) are brought into scope.
This notation also allow us to spicify the types of these newly introduced entities explicitly.

\begin{enumerate}
    \item {\lstinline|Bool|} has the type of {\lstinline|Set|}\footnote{{\lstinline|Set|} is the type of small types, and {\lstinline|Set₁|} is the type
of {\lstinline|Set|}, and so on. They form a hierarchy of types.}
    \item {\lstinline|true|} has the type of {\lstinline|Bool|}
    \item {\lstinline|false|} has the type of {\lstinline|Bool|}
\end{enumerate}

\paragraph{Pattern matching}
% [draft]
Similar to Haskell, datatypes are eliminated with pattern matching.

Here's a function that pattern matches on {\lstinline|Bool|}.

\begin{lstlisting}
not : Bool → Bool
not true  = false
not false = true
\end{lstlisting}

Agda is a \textit{total} language, so partial functions are not allowed. Functions
are guarantee to terminate and will not crash on all possible inputs. The following
example won't be accecpted by the type checker, because the case {\lstinline|false|} is missing.

\begin{lstlisting}
not : Bool → Bool
not true  = false
\end{lstlisting}

\paragraph{Inductive datatype} Let's move on to a more interesting datatype with inductive definition. Here's the type of natural numbers.
% [draft]
\begin{lstlisting}
data ℕ : Set where
    zero : ℕ
    suc : ℕ → ℕ
\end{lstlisting}

Addition on {\lstinline|ℕ|} can be defined as a recursive function.

\begin{lstlisting}
_+_ : ℕ → ℕ → ℕ
zero  + y = y
suc x + y = suc (x + y)
\end{lstlisting}

% {\lstinline|suc zero|} serves as the number "1", {\lstinline|suc (suc zero)|} as "2", and so forth.
We define {\lstinline|_+_|} by pattern matching on the first argument, which results
in two cases: the base case, and the inductive step. We are allowed to make
recursive calls, as long as the type checker is convinced that the function
would terminate.

The underlines surrounding {\lstinline|_+_|} act as placeholders for arguments, making
it an infix function in this instance.

\paragraph{Dependent functions and type arguments}
% [reviewed: 1]
Up till now everything looks much the same as in Haskell, but problem arises as
we move on to defining something that needs more power of abstract. Take identity
functions for example:

\begin{lstlisting}
id-Bool : Bool → Bool
id-Bool x = x

id-ℕ : ℕ → ℕ
id-ℕ x = x
\end{lstlisting}

In order to define a more general identity function, those concrete types have
to be abstracted away. That is, we need parametric polymorphism, and this is
where dependent types come into play.

A dependent type is a type whose definition may depend on a value. A dependent
function is a function whose result type may depend on the value of an argument.

In Agda, function types are denoted as:

\begin{lstlisting}
A → B
\end{lstlisting}

Where {\lstinline|A|} is the type of domain and {\lstinline|B|} is the type of
codomain. To make {\lstinline|B|} dependent on the value of {\lstinline|A|}, the
value has to \textit{named}, in Agda we write:

\begin{lstlisting}
(x : A) → B x
\end{lstlisting}

As a matter of fact, {\lstinline|A → B|} is just a syntax sugar for {\lstinline|(_ : A) → B|}
with the name of the value being irrelevant. The underline {\lstinline|_|} here
means "I don't bother naming it".

In this instance, if {\lstinline|A|} happens to be {\lstinline|Set|}, the type
of all small types, and the result type happens to be solely {\lstinline|x|}:

\begin{lstlisting}
(x : Set) → x
\end{lstlisting}

Voila, we have polymorphism. And thus the identity function can now be defined as:

\begin{lstlisting}
id : (A : Set) → A → A
id A x = x
\end{lstlisting}

{\lstinline|id|} now takes an extra argument, the type of the second arguement.
{\lstinline|id Bool true|} evaluates to {\lstinline|true|}

\paragraph{Implicit arguments}
% [reviewed: 1]

We have implemented an identity function and seen how polymorphism can be modeled
with dependent types. However, the extra argument that the identity function
takes is rather unnecessary, since its value can always be determined by looking
at the type of the second arguement.

Fortunately, Agda supports \textit{implicit arguments}, a syntax sugar that could
save us the trouble of having to spell them out. Implicit arguments are enclosed
in curly brackets in the type expression. We can dispense with these arguments
when their values are irrelevant to the definition.

\begin{lstlisting}
id : {A : Set} → A → A
id x = x
\end{lstlisting}

Or when the type checker can figure them out when being applied.

\begin{lstlisting}
val : Bool
val = id true
\end{lstlisting}

Any arguments can be made implicit, but it doesn't imply that values of
implicit arguments can always be inferred or derived from context. We can always
make them implicit arguments explicit when being applying:

\begin{lstlisting}
val : Bool
val = id {Bool} true
\end{lstlisting}

Or when they are relevant to the definition:

\begin{lstlisting}
silly-not : {_ : Bool} → Bool
silly-not {true}  = false
silly-not {false} = true
\end{lstlisting}

\paragraph{More syntax sugars}
% [draft]
We could skip arrows between arguments in parentheses or braces:

\begin{lstlisting}
id : {A : Set} (a : A) → A
id {A} x = x
\end{lstlisting}

And there is a shorthand for merging names of arguments of the same type, implicit or not:

\begin{lstlisting}
const : {A B : Set} → A → B → A
const a _ = a
\end{lstlisting}

Sometimes when the type of some value can be inferred, we could either replace
the type with an underscore, say {\lstinline|(A : _)|}, or we could write it as
{\lstinline|∀ A|}. For the implicit counterpart, {\lstinline|{A : _}|} can be
written as {\lstinline|∀ {A}|}.

\paragraph{Parameterized Datatypes}
% [draft]

Just as functions can be polymorphic, datatypes can be parameterized by other
types, too. The datatype of lists is defined as follows:

\begin{lstlisting}
data List (A : Set) : Set where
    []  : List A
    _∷_ : A → List A → List A
\end{lstlisting}

Note that the scope of the parameters extends over the entire declaration, so
they can appear in the constructors.
Here are the types of the datatype and its constructors.

\begin{lstlisting}
[] : {A : Set} → List A
_∷_ : {A : Set} → A → List A → List A
List : Set → Set
\end{lstlisting}

Where {\lstinline|A|} can be anything, even {\lstinline|List (List (List Bool))|},
as long as it is of type {\lstinline|Set|}.

\paragraph{Indexed Datatypes}
% [draft]

% Indexed datatypes, or inductive families, allow us to not only
Let's look at something more interesting, a datatype that is similar to
{\lstinline|List|}, but more powerful, in that it can tell you not only the type
of its element, but also its length.

\begin{lstlisting}
data Vec (A : Set) : ℕ → Set where
    []  : Vec A zero
    _∷_ : {n : ℕ} → A → Vec A n → Vec A (suc n)
\end{lstlisting}

{\lstinline|Vec A n|} is a vector of values of type {\lstinline|A|} and
has the length of n. Here are some of the inhabitants:

\begin{lstlisting}
nil : Vec Bool zero
nil = []

v : Vec Bool (suc (suc zero))
v = true ∷ false ∷ []
\end{lstlisting}

We say that {\lstinline|Vec|} is \textit{parameterized} by a type of {\lstinline|Set|}
and is \textit{indexed} by values of {\lstinline|ℕ|}. But it's not obvious how indices are
different from parameters.

Parameters are \textit{parametric} (no pun intended), in the sense that, they
have no effect on the "shape" of a datatype. The choice of parameters only effects
which kind of values are placed there. Pattern matching on parameters won't reveal
anything useful about their whereabouts. Because they are \textit{uniform} across
all constructors, you can always replace the value of an parameter with another one
of the same type.

On the other hand, indices may affect which inhabitants are allowed in the
datatype. Different constructors may have different index. In that case, pattern
matching on indices may yield important information about their constructors.

For example, if there's term whose type is {\lstinline|Vec Bool zero|}, then
we certainly know that the constructor must be {\lstinline|[]|}, and if it's
{\lstinline|Vec Bool (suc n)|} for some {\lstinline|n|}, then the constructor
must be {\lstinline|_∷_|}.

Then we could for instance define a {\lstinline|head|} function that cannot crash.

\begin{lstlisting}
head : ∀ {A n} → Vec A (suc n) → A
head (x ∷ xs) = x
\end{lstlisting}

Note that parameters could be thought as a degenerate case of indices whose distribution
of values are uniform across all constructors.

\paragraph{With abstraction}
% [draft]

Say, we want to define {\lstinline|filter|} on {\lstinline|List|}:

\begin{lstlisting}
filter : ∀ {A} → (A → Bool) → List A → List A
filter p [] = []
filter p (x ∷ xs) = ?
\end{lstlisting}

We are stuck here, because the result of {\lstinline|p x|} is only available in
runtime. Fortunately, with abstraction allows us to pattern match on on the result
of an intermediate computation by adding the result as an extra argument on the
left-hand side:

\begin{lstlisting}
filter : ∀ {A} → (A → Bool) → List A → List A
filter p [] = []
filter p (x ∷ xs) with f x
filter p (x ∷ xs) | true  = x ∷ filter p xs
filter p (x ∷ xs) | false = filter p xs
\end{lstlisting}

\paragraph{Absurd patterns}
% [draft]

There are two special types, the \textit{unit type} and the \textit{bottom type},
denoted as {\lstinline|⊤|} and {\lstinline|⊥|}, which as 1 and 0 values respectively.

\begin{lstlisting}
data ⊤ : Set where
    tt : ⊤

data ⊥ : Set where
\end{lstlisting}

Where {\lstinline|⊤|} has only a value, {\lstinline|tt|}, and {\lstinline|⊥|} has none.

These types may seem useless, and without constructors, it is impossible to
construct an element of {\lstinline|⊥|}. What is an type that can not be
constructed good for?

Say, we want to define a {\lstinline|head|} on {\lstinline|List|} that is
statically checked and won't crash on any inputs. So we need to make sure that
all inputs are not empty. But unlike on {\lstinline|Vec|}, without indices, we
need other means of guaranteeing that the list is not empty. Naturally we would
come up with a predicate like this:

\begin{lstlisting}
non-empty : ∀ {A} → List A → Bool
non-empty []       = false
non-empty (x ∷ xs) = true
\end{lstlisting}

The problem is that we can only know if a list is null in runtime. However, with
 {\lstinline|⊤|} and {\lstinline|⊥|}, we could instead define a predicate like this:

\begin{lstlisting}
non-empty : ∀ {A} → List A → Set
non-empty []       = ⊥
non-empty (x ∷ xs) = ⊤
\end{lstlisting}

Notice that now this function is returning a type. Now {\lstinline|head|} can be
defined as:

\begin{lstlisting}
head : ∀ {A} → (xs : List A) → non-empty xs → A
head []       proof = ?0
head (x ∷ xs) proof = ?1
\end{lstlisting}

\section{Num : a representation for positional numeral systems}\label{representation}
% [draft]

% \subsection{Time complexity}

\subsection{Digits}
% [draft]

Numbers in positional numeral systems are composed of a series of symbols
so-called \textbf{digits}. A system can only have \textbf{finitely many} digits.
Operations on these digits, such as addition, must be \textbf{constant time}.
Notice that the problem size of time complexity we are discussing here refers
only to the value of a number. And since the number of digits is independent of
the value of a number, time complexity of functions on digits should be trivially
constant.

\paragraph{Fin}
To represent a digit, we use a datatype that is conventionally called \textit{Fin}
which can be indexed to have some exact number of inhabitants.

\begin{lstlisting}
data Fin : ℕ → Set where
    zero : {n : ℕ} → Fin (suc n)
    suc  : {n : ℕ} (i : Fin n) → Fin (suc n)
\end{lstlisting}

The definition of {\lstinline|Fin|} looks the same as {\lstinline|ℕ|} on the term
level, but different on the type level. The index of a {\lstinline|Fin|} increases
with every {\lstinline|suc|}, and there can only be at most {\lstinline|n|} of
them before reaching {\lstinline|Fin (suc n)|}. In other words, {\lstinline|Fin n|}
has exactly \textit{n} inhabitants.

Our digits are simply {\lstinline|Fin|}.

\begin{lstlisting}
Digit : ℕ → Set
Digit = Fin
\end{lstlisting}

Binary digits for example can be defined as:

\begin{lstlisting}
Binary : Set
Binary = Digit 2

零 : Binary
零 = zero

一 : Binary
一 = suc zero
\end{lstlisting}

But these digits bears no meaning without converting to {\lstinline|ℕ|}.
Here {\lstinline|d|}

\begin{lstlisting}
Digit-toℕ : ∀ {d} → Digit d → ℕ → ℕ
Digit-toℕ x o = toℕ x + o
\end{lstlisting}

% number of inhabitants. \textit{Fin} would do that just fine.

% Because we would like to index the number of symbols
%
% To represent a digit, we need a datatype that can be indexed to have an exact
% number of inhabitants. \textit{Fin} would do that just fine.



% In fact, since there are only a finite number of digits,


\subsection{Bases}
\subsection{Offsets}
\subsection{Number of digits}

\section{Properties of Num}
\subsection{Maximum}
\subsection{Bounded}
\subsection{Bounded}
\subsection{Views}

\section{Conclusions}\label{conclusions}

\bibliographystyle{abbrv}
\bibliography{thesis}
\end{document}
